{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBuXlNAuwAfe",
        "outputId": "60d65dff-76a6-4fcf-ea30-a3d4c4e3dbe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.66.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: yake in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.11/dist-packages (1.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from yake) (0.9.0)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.11/dist-packages (from yake) (8.1.8)\n",
            "Requirement already satisfied: segtok in /usr/local/lib/python3.11/dist-packages (from yake) (1.5.11)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.11/dist-packages (from yake) (1.1.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai transformers torch spacy yake ffmpeg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"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\"\n"
      ],
      "metadata": {
        "id": "dNgVzjqFwBSx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "audio_path = list(uploaded.keys())[0]  # Get uploaded filename\n",
        "print(\"Uploaded file:\", audio_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "8UmWjbUUwrst",
        "outputId": "7115062e-68d5-4f70-9958-be785be9c2ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d49db248-f1fb-4e54-849b-e438ef6879b3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d49db248-f1fb-4e54-849b-e438ef6879b3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7f8e25ebf714>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maudio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get uploaded filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Uploaded file:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "ENAPy28SyFJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "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\n"
      ],
      "metadata": {
        "id": "FIrxeN5UzDno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"  # Replace with your key\n"
      ],
      "metadata": {
        "id": "OJVlwFL8yRr3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Upload audio file\n",
        "audio_path = list(uploaded.keys())[0]  # Get the filename\n",
        "print(\"Uploaded file:\", audio_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "lAinwRJ-ylrS",
        "outputId": "828b8fe0-fa69-4623-97fa-81487772b2b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-06e24eef-a5e7-4102-bdb4-d65567b3249c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-06e24eef-a5e7-4102-bdb4-d65567b3249c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 12806852-44100-1-f5e213d65f1fa.mp3 to 12806852-44100-1-f5e213d65f1fa (3).mp3\n",
            "Uploaded file: 12806852-44100-1-f5e213d65f1fa (3).mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper\n",
        "\n",
        "import whisper\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xOCkLHWzRmL",
        "outputId": "38d96df6-785d-4136-a897-21cdc3b587bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"base\")  # Load Whisper model\n",
        "result = model.transcribe(audio_path)  # Transcribe the uploaded audio file\n",
        "\n",
        "transcript = result[\"text\"]\n",
        "print(\"\\n🎙 Podcast Transcript:\\n\", transcript)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo-viJMlzh-R",
        "outputId": "b2851166-fa5b-402e-8de3-7ac64ffbda8d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎙 Podcast Transcript:\n",
            "  Welcome to episode 82 of Sound Out Wave, the first podcast to reach Flan Earth from Cybertron. I'm Nell and I'm Great at Transformers. And I'm Greg and I'm getting better at Transformers. And this week we bid farewell to you till all are won with issue 12. Winblade, what is this? This, you know this ain't even Winblade. That ain't Winblade, that's Vigil. Why you, why you hugging Starscream's face? Vigil is kind of, he's a little too hype about this. He's like, little too diesel here. Starscream is just carrying Vigil him on his back, trying to get him out of the concert because he's going to Buck Wild, had a little too much E. And now he needs to drink some water and Starscream was like, oh he owes me for this one. That's right, that's something he'll keep in his back pocket. Vigil him, if we should set the stage, Starscream is going into Winblade's head because Winblade is dealing with Carcer slash Vigil him inside their, their fighting and Iraq, Iraq knit is saying, okay I can get you in there, no problem. Right, well and that, yeah that was the interesting thing, that's kind of where we left off was, of course, Winblade and Vigil are fighting within the confines of Winblade's mind. They thought initially she was catatonic and I mean she is, she's not physically responding to anything but mentally, it's just going off in there because we have these two great forces battling for control over her mind and yes, Iraq knit let us know that like, somebody has to go in there and fight off Vigil him and help out Winblade and that was kind of where we left off, a little bit of a cliffhanger I'm like, well how's this all going to break down? And it's really great on this our last, Tilly and all, to all our one role call, we just have Starscream and we just have Winblade. They're the only two people in this comic now. They're the only ones we have to worry about. Luckily, we will get to talk about a few other bots and it's really cool, I'm excited to get to it. There's some cool moments. We do open with the sort of charred cityscape of Winblade's mind. Yeah. I do like that there's a little Texans that just says, raw. It's, yeah, Vigilins just kind of giving a little roar there. It's really neat. I don't know, again, there are these moments in the comics where I don't know if the writer kind of set the scene or if the artist kind of took control, but we are looking at presumably Caminus, which is the cityscape of Winblade's mind. And there's this building and it's a little bit horrific. It's just her head on top of this building, like almost like she's part of it. It's very surreal, very, very much this kind of nightmare, you know, adds to this nightmares that we're in within her mind where these two are fighting. And then we go to this next panel where we see that we could presume that that's where she and Vigilins are both that because her her mind, it's, it's not because like it's her, and this is all like probably not literal, like it's all just, right, but like that's her brain, right? That's her brain and like it has her eye markings on it. It's very cool. Like it's all like at, at the same time, it is literal and also very figurative. And it's, again, I don't know if this was Margaret's direction or if this was Sarah just like taking the reins, but either way, it's striking. Right. And fantastic visuals through this entire thing. The next panel also has really cool stuff because we see like Carcer and Vigilum and this like corrupted wind blade, each of whom are talking about, all of whom are Vigilum. Yeah. But they're each talking about Vigilum's different like motivations, like one serving Lege Maximow, two getting vengeance on Metriplex and three, like taking over the mind of wind blade and carrying out hergels, which was promised by Vigilum in the last issue, where it was like, if we work together, we can do what you want to. Right. Like let me take over and you'll get your end goal, which he tried to convince her if we'll remember that like she should be ruling Cybertron. That was kind of his pitch to her. Let's both get what we want here. But like, if he's gonna destroy Cybertron, it doesn't really like, there's a huge flaw I see immediately, my dude, in your plan here. But yeah, he's, you know, of course they're fighting for her mind and he's just letting her know like either join with me, like this is kind of where his whole thing is, like if she doesn't join with him, she'll just, it should just be kind of killed. Like out. Yeah, set aside. And he'll still get what he wants. And of course she is saying like, this is still her mind. She knows what he's trying to do. Basically saying that like, you are trying to get me to give into you, so you can have whatever you want. But I, I know I can still fight you. I know I can still win this. And really to her, winning this is also could just be a matter of lasting long enough until they both die, because he's letting her know he's kind of reminding her like, your body is shutting down, because it can't handle what's going on in here. And she's fine with that. If that means he does not get out. And yeah, she very much lets him know like, I don't care if we both die. As long as you don't get to destroy everything, that's a normal sacrifice for her. Like you say, absolutely. Yeah. But then his back explodes. He's suddenly shot. And a hero comes to save the day. And he says, cheers love the capillaries here. I love this because he is in such a like, I don't give a shit about this pose. Yeah, just like wind blade on here. It starts green by the way. In case people aren't looking in the comic with us. Yeah, both of his nil rays are kind of smoking. He looks great. He was like, yeah, whatever. I just so happen to be in your brain. It's not like I came here to save you. Yeah, I was just throwing it, strolling through like wind blade caminus and was like, oh, I guess I should probably see what my friends up to. The other thing, I don't know if it's because I've seen people draw him this way or what. But he looks like he's wearing hot pants. And so I just imagine he also has on roller blades. Well, it was just like making his way down through Santa Cruz. Like, well, that's a given. Yes, absolutely. Absolutely. Wearing hot pants. Yes, he's absolutely wearing roller blades. He did take off the visor. He's usually going on like a neon green visor. And he was like, oh shit, I'm going to set this aside. So it doesn't get, you know, caught in the crossfire. But yes, he absolutely looks like that. So that's just how he does. That's Starscream, baby. But yet, yes, wind blade is one shock to see him here. Two pistes to see him here. He's to see him here. She's like, no, no, no, no, my dude, I have been trading to like live in minds for decades. I had this figured out. Yeah, you just rolled in here. I don't know why you think you can help me out. I have this under control. And of course, then they just start fighting because this is what they do. He of course thinks that she's being ungrateful. And as far as, and I love this because this is exactly how Starscream thinks. Like he's like, no, like there's something this dude is fucking shit up. And so we kill him. Like I came here to kill him so we can fix everything. Which I'm the chosen one. It never enters his mind whether or not he'll be able to kill him. No, he's just going to go kill him. Like that. Yeah. Like point A point B. Let's go. And so of course, naturally, what wind blade fears is true. She's trying to warn him. Like, huh, okay, I've been able to fight this guy because I'm kind of trained in like how to navigate minds and like hold up your defenses. Right. And he's a city. I can city speak. Yeah. And Vigilum, yes, he kind of brings he brings to the forefront exactly what she's saying. And he's like, yeah, thanks for showing up. Now I'm just going to use you as a conduit to get the hell out of here and get my plan going on here. And it's terrific in these next couple panels because of course, Starscream. Starscream's not going to stand down to the do the Starscream. That's not what he's about. And he's saying like, no, you're not like other better people have tried. Let me tell you. And of course, Vigilum can tap into this stuff. Now that Starscream's mind is part of this equation. Right. He can get into some memories here. And of course, he's going to tap into the person that Starscream fears the most. And we all know who that is going to be. Bumblebee. If Bumblebee is surprising everybody. It is the small yellow horned Bumblebee. Totally harmless. Walks with a cane. To the casual viewer, you would not suspect. Of course, it's Megatron. I do want to point out we get this really great. I know I say this every month that we get to talk about at all. But damn, I love the way Sarah draws these bots. The look of fear on Star Trek's face is fantastic. We don't get to see a panic Starscreen very often. Or at least one caught off guard or like a little, yeah, he's a little afraid here. It's worked. Vigilum did it. He even says, you're not real, you can't hurt me. I know that. Like he's trying to convince himself as much as he is trying to say it to Vigilum, who of course, yes, has assumed the form of Megatron and like classic Megatron. That's a good looking Megatron. Oh God, he looks great. Sarah draw more Megatron, please. And also, yeah, just you know as soon as this shit started going down, it was like, Hell yes, I am here for this fuckery. This is what I signed up for. The dynamic between Megatron and Starscream has always been just such a great and interesting one. And I've loved it from the beginning. I think many people have, regardless of how you see them, it's always been a really, really interesting and powerful dynamic, of course. So it's great to see even this panel where we first see that he's of course turned into Megatron. Starscream looks so small in front of him. He's not just Megatron. He's this massive star of Megatron. Yeah. And of course, he uses that fusion cannon, which we all know, Megatron, now does not use anymore, but the one that Starscream would fear this classic all-hale Megatron era Megatron still has it and he shoots him with it, of course. And it's enough to like blast them into Starscream's minds. Yes. And so we all fall into Starscream's brain and Winblade points out that, you know, Vigilins already rewriting his brain because Starscream does not have as much strength in this particular style. Winblade does so immediately she goes in. And it's K-On. Yes. And which I love a couple things about this. I love first of all, like it's very, very cool to me that their mindscapes look like, quote unquote, their cities. Like she looked, like hers looked like Kamenus and his looks like K-On, which also sidebar, they, K-On did come up in the comics. Nobody lives there now, but this was in the the Titans Return comic, the one shot that we missed for whatever reason. That one's on me. But so Winblade has seen K-On and she's seen it in its current decrepit state where nobody lives there, but she has been K-On on Cybertron currently. But so I it's interesting that Starscream's mindscape looks like K-On for what it's worth usually and maybe not usually, but oftentimes in the Transformers Continuities Starscream tends to heal from Voss, which I thought was interesting that his mindscape is K-On, but maybe my reasoning for possibly either he's he just is from K-On and what Mergut has cited or that he just kind of recognizes K-On as his own because that was the first city to fall to the decepticons. That's cool reasoning as well. Right? So like yeah, I'm done with either of those, so just some tidbits for everybody there. But yeah, that's where we find ourselves this kind of Hellscape K-On. Vigilum is also down for those and he is just ripping Starscream to shreds, just tearing him apart. Yeah, like literally tearing him apart. And he has an interesting line, he says, Maximus says to be aware of Vots who change their skin too often, they're trying to hide a rotten core. Referring directly to Starscream, changing design in terms of like his transformed mode so often. Which is yeah, we can see even as he like every time he priced him a Goliath, which also he has damn ladies. Like he's just, Mergutron is just tearing pieces off of him and every time he does, he reverts to a different version of Starscream. Until in the end here we see he's kind of the the same Gen 1 Starscream to match this Gen 1 Megatron that we saw back in All-Hale Megatron. But also to that point saying they're trying to hide a rotten core, it's kind of, I mean, and maybe this wasn't what she intended, but it reminds me also of the fact that like Vigilum, not even his own accord though, kept changing because as Carcer, Alita and her crew kept essentially like changing and shifting him and putting new parts on him and you know what I mean, adding to him and changing him constantly and he was hiding Lee's maximum of the core. Which again, I don't know if that was intentional, but I'm like that's kind of a cool mirror that might be neat subtext kind of put in there that like even he doesn't realize that he's saying it. I love it. And so we are stomping Gen 1 Starscream here and we do see an exposed spark. Yes, he breaks his cockpit open enough to see it shining there and he says it's just as unremarkable as any other. He's about to destroy it and our girl, the hops in and she grabs it. Right. And he does say it's just as unremarkable as any other. Anytime you kill a king, like in a gory way, take out their heart and make sure everybody knows. Looks just like everybody else's heart. That's the way. That's some Game of Thrones shit and if you don't do it, I'm going to be mad at you. If you kill a king and you don't take the opportunity to point out, like you killed a king and you didn't do this one step. Didn't like bring about like, hey everybody, not so immortal, huh? Yeah. What do you? Why would you even bother to kill a king? I ask you. Like what a wasted. But yes, Winblade does jump in and saves his spark. The rest of him not so much. Yes, the rest of us gone. Even as she is grabbing it, it looks like he's not even there, which I think might be the case. Because again, in these mindscapes, everything is very surreal and shifting constantly. So his body might have already been gone and been purely just left to this spark, which she has grabbed and was kind of cradling like she's holding it in both of her hands. And of course, Vigilins mocking her for it. And he's saying that, you know, she, well, Caminus was a loser too. So it doesn't surprise me that you're a chump and like you think that you're going to make any difference here. But it's cool because he's then he kind of is, he punches the ground and like starts to kind of rewrite Starscream like she was afraid of, like she was worried about. Yes, we can see him taking over Starscream's mind, you know, really visually awesome way. It's really cool. There's this like the cracks around him start forming wide shot, wide shot. We can see it's forming an eye and then we can see it's forming a face. It's his face and yeah, he's saying that he's adaptable. He will just take over Starscream. Like he'll just wake up as this form now. He doesn't need her. He'll just wake up a Starscream. And it'll be even better. Now he doesn't have to go through that extra step of taking that step. Now he's got him for a cybertron. Yeah, exactly. And Winblade is not stopping him because she's focused on the spark she is holding. Yeah, because it kind of mocks her. He's like you don't even have a weapon. Like you're holding a baby essentially. And that's not going to help you. And she's like, don't worry. I got it unlocked flashback time. Flashback time. It's more of an irleafing. Yeah, we love her. If she's buffing tall and cool. And she's saying like, hey, guess what? Building things is more powerful than destroying things. And so the creation of a thing. Yes, yes. Soul is prime behind her. It's dope. I'm digging right like chords coming out of the back of her helmet. It's very, very cool. Soul is prime. dope. But yeah, she's, but yeah, it's she's this is what we've heard before. There this belief that the chemians hold about. Soul is in particular, or being their prime, is that like the more when you forge things as Soul is dead, you just keep working at it until all this lag falls away. So essentially, you just keep working the metal. You keep working in the way. Yeah, you keep refining refining refining until you get this beautiful pure thing. And that's the best thing that you can do is create. And she says that a spark is shaped by all who touch it. And so we also see a flashback explaining sort of what she sees about Starscream Spark in particular that he was cold constructed. Yeah, she's this is kind of a literally a hands-on. We can see your touching Starscream Spark and seeing firsthand how cold construction works. Because she's saying in her belief, prime is should be the first one to touch a spark. And then this is where then the hot spots light up and from there, then they get sometimes literally forged now that we know with Annode. But now of course, yeah, she's seeing cold construction happen, which we do know, we learn back all the way back in more than museum. Starscream is constructed cold. And so we can see his this spark that she's now holding being placed in this seeker body of which there are many, which you know, we know that there are a bunch of seekers who all look the same. And so yeah, she's she's a little bit appalled by this. It's right. She feels bad. And it's it's an interesting stance to take on cold construction, which is kind of had like a stigma attached to it in some stories. Yeah, like at once upon a time, there was yeah, absolutely a stigma. But had like a whole yeah, it was like a social right. And we and even it was Tyrest who was trying to eliminate all cold constructed bots, right? Yes, most recently, yes, it was Tyrest who because this is it's not a new concept. There are there have always been bots who consider people constructed cold to be lesser than those who are yeah, born of hot spots and what have you forged. And so yes, so Tyrest, when Tyrest tried to set off his machine or he did set off his machine, that was to burn out cold constructed sparks, which of course were created from the matrix. And that's at how all of these cold construction bots were created. Right. So that's where we as far as the show has for have for sure seen the yes, some people have a problem with it. And it's interesting to see like the idea is that if your cold construction you never really got a chance to form what you are, which is a little later in the issue, certainly. Yeah. But she says the line where is that what you were seeing escaped from a foreign skin, the belonging that you thought was lost forever, which is interesting, the idea that Starscreen didn't really get to decide who he was. Which is yeah, it's true. It's true of him. It's true of Megatron. You know, there were these bots just placed in these bodies and it is honestly not a thing that has really been I mean, I'm sure other people have thought of it. I hadn't really thought about before, you know, because yeah, it hasn't been super addressed in this. But no, it does. I know I brought up this parallel before reminds me of Loki. Like Loki is the God of Mischief and he's not allowed to be anything else. And Starscreen has to be what he is because he feels he was born into this. And so that's an interesting character like Vane to explore is the idea of like who would Starscreen be if he could decide that for himself. Right. Like if his spark had naturally chosen a form, would it be this or would it have been with things have been different? Too bad. We'll never see what that looks like. We'll never see. But it's a really sweet moment. The way, and even I love this panel of her looking at the spark and saying she kind of says like, no, whatever he was, even if he didn't like what he ended up being put into, it was if he had turned inward, like it was still right here. Like his spark is still him, even if he didn't feel like that. I matched, which I do think could also be a really interesting and thoughtful commentary, you know, even like we touched on it before with an noted mug and the gender pronouns, like this could be another right like the thing like that. Like Starscreen didn't get to choose. He just got put here. But and the idea being that like the spark, which is kind of a thin metaphor for a soul, like there are there are things on there that are imprinted that even altering the other forms like like she says, you can look inside and see what you are like he just never did. Right. This is Starscreen. She's holding Starscreen, which is adorable. And it's great because it kind of like even when we take a step back and look at her through all of this, even then when we hop to this next page, we see she's taken so much power back. It's almost like she needed like in seeing Starscreen in trouble and seeing all of this happening in front of her. It's given her kind of a moment to realize her own power because she's now she looks like she's on it now. And she even says like, you know what? No, I'm not a warrior, but I do worship a Smith. And there's no there's no forage purer than a spark she says. And she takes this hammer. This I don't know if that's what you would like. Yeah, yeah, it's a hammer. And yeah, she starts she hits Starscreen Spark. And then we see his greatest fear return again in the form of a couple of years. But no, yeah, she's saying the spark remembers everybody who touches it. Right. Which is what she said a moment ago. And he is like, why don't care about bubble? They bubble these are going to stop me. I've already in Starscrew's brain. And she's like, why am I everyone who touches it? And this is really cool. Oh, god, it's so cool. Like first of all, look at the same. We're going to do. Yes. So this is, she says every enemy, every ally, every life that touched his left behind its trace. So basically, everyone who has made an imprint on Starscreen soul is here. And she's again, she's just hitting the spark. And it is cool because the ground is even like, it's him. So like the ground is up and like kind of also touching the spark now. Um, I do just want to take a quick sidebar and say jet fire being in this list is everything because in the comics, I don't think they've interacted. But in Gen 1, they were said to be old friends. A lot of people have been like, one they used to date. Um, I think it's something I've brought up before on the show. So I very, very much appreciate that though we've never seen it in the comics, jet fire being here does kind of hint at this, because a lot of people still really love this idea of jet fire and Starscrew having some sort of pass together. So I appreciate very much that jet fire is in this list of all these other people. Right. I know. For a fact, have interacted with Starscrew and meant a lot to him in some way or another. Right. Like to me, it wasn't just like Starscrew's interact with us. People like these people have shaped Starscrew's life. And we've got so many. We've got so good. Yeah, seeing both the waves and real jet fire. ravages here. Yeah. Chromias here. Yeah. Which implies that that decision weighed way heavier on Starscrew. Then it might have come across like it's a really great multi-dimensional panel right here. Yeah. There's a lot going in there. It's brilliant. And I love it. And it's really beautiful. Everybody looks great. Of course. Yeah. It was it was a very it's a very powerful visual, a very great choice being said here. And then of course, yeah, he's, Vigilum is a little, he looks a little bit more worried now. And even though he's like denouncing them, he's saying like, no, I can't like these are they're not even real. They can't touch me, but they're all going in attacking him anyway. And he does say that they can't like, I can't be defeated by them. And she's saying, well, this isn't about you and you're defeat. This is we're trying to make something here. Like, I don't give a shit about you. You're a waste of space. But we have something powerful here. Because again, like the Mr. Supply said, the best thing you can do is create something pure. And she hits that spark again because she's forging. And a bot is formed. A bot is formed. Look how beautiful. Not sure who this is, but the stranger shows up. And he's big. He's big. So this is this is presumably we can assume Starscreens form where his spark allowed to develop without cold construction essentially. This is, yeah, StarScreen major. And I think I'm pretty sure I speak for both of those when I say this. Hot, really hot. Like, so fucking hot. Which is super attractive. Like part of it is like a given because again, they're showing all these bots. So everybody's just default fucking Gorgeau. But like, yeah, no, he looks great. He looks real good. And still has even that same little face. Like, it's still that there's something about him that's still StarScreen esque. Right. I mean, he's still clearly a jet. Yeah, yeah, he's a flyer. And he's still got a red, white, and blue color scheme going on. There's a lot more blue. Yeah, the other color here. He's just much, yeah, he's much bigger. He's but like still streamlined. I don't know. It's interesting. It's really great design. I really love it. I really appreciate it. And it's fantastic because even when Blader dressing him, she looks kind of odd. She's and she says it's nice to finally meet you, StarScreen. Which is really sweet. It's a really what a great issue for the two of them. And of course, vigilance trying to just cover it in these ghost robots is like, you can't that's still not enough hang on. Let me just crawl out of here a moment. And of course, StarScreen steps on him. Right. He's like, hey, this is my brain dip shit. Get out. Yeah, get the fuck out of here. He steps on him so hard he launches him back into wind blades mines. Which is where we pick up again in front of that building with her head on the top of it, which is where her her brain module was being housed. Literally or figuratively, we're still not sure. Sure. Yes. And so she realizing as she said a couple of pages ago, there's no forage hotter than a spark. Exposes her own spark. Yeah. She yeah, that that head of hers on this tower kind of breaks the tower apart. And it's just her now she's the Titan. She is the one who's the size of a she's the captain now. She is the captain now. And she picks him up. vigilance still a little tiny. And she's saying like, I kept trying to fight you, but I just had to embrace you. And like you said, yeah, she she exposes her own spark. And she as one doesn't a forage brings him inside. And yeah, she's going to burn away this leg. Yeah, the impurity melts away. She shows him in. And then they wake up. Yeah. It turns out it was all a dream. It was all just a dream. Wind blade wakes up, goes to the shower, star screams in the shower. So they both wake up and uh, air act and it's like, oh, hey, I mean, congratulations. You you did it. That was dumb. It was fun to watch. Like I'm I'm too be real. Can I just be real with you both in moment? I'm a mixture. I'm glad. I'm a mixture of both awake. And star screams like, well, you get the fuck out of here, please. And she's like, all right. And don't got to tell me twice. Only he did. And she leaves. Right. And it leaves just the two of them waking up, unhoking themselves from whatever machinery air actinid had going on in here. And uh, yeah. Right. They're pulling out their matrix brain plugs. And he even says, I mean, it's not like I like you or anything wind blade. Yeah. Like everything that we just did don't like think nothing of it. We can just go into a new title and not address any of this. And she's like, come on now. Don't be like that. You saw your best you you saw your your true. You could be. Yeah. And so of course I'm going to remember that. And she's saying, you know, that doesn't change everything. Well, then you're you're a bigger dumb dumb than I thought you were. And she just starts taking off. He's like, wait, hold on, where are you going? Um, and this was as much as Starscream saw his true self. She's also like, I'm gonna go do whatever the hell wind blade feels like doing. Uh, I'm not gonna let you tell me what to do. And he's like, are you threatening me? She's like, no, no. I mean, unless you unless you move on me. Yeah. I hope that I hope that's not a threat. Like, and she's saying, you know, I'm done holding back. I'm, I feel like I can do good in this world. And I have confidence. And yeah, she's gonna tell people what I have to say. Yeah. And she's done speaking for the people. She says, uh, Mr. Siflaine, Max, Metroplex, whoever else, like she has a voice to you. She doesn't just speak for other people. Solace and Primus gave her truth to you. She's not just a city speaker. She's a wind blade speaker. She's a wind blade speaker now. And she hopes that you will agree with what she has to say. And can I just say you're doing amazing, sweetie. Because that's where we leave off our girl strutting out the door to close out till all our one. That's till all our one a K a how wind blade got her groove back. That's actually the title of this issue. We never see it come up in the pages. Yeah, we don't see the title drop, but that's what it is. That's what it is. Just imagine it. If you take the first letter of each word said by wind blade throughout the, no, I don't think that works. We could make it work. Um, but yeah, that'll that's that's 12 and of course, yes, amazing. What a great issue. Um, it's it's right. It's quick, but it packs a lot in there and it does it with a lot of layers, which is right. And impressive. Right. In like a really cool way to kind of bring these two characters specifically to a place where and sure everybody's excited to see where they go next. And that's kind of where we find ourselves now. Um, of course, that was an easy issue to talk through just because it's like even on my notes, I have like my one note here just says this issue needs no notes like because I just don't there was nothing to like write down and, uh, you know, have commentary about necessarily. It was just it moved so seamlessly. Um, but that's, you know, kind of where we in a way precariously leave them because of course, Merrickard's done writing. Like this isn't we're going to have the annual, but for now, where this is at till all are one is done. And uh till all are done till all are done. It turns out all are one now. We did it. That's what it all became one. What do you know? Great job, everyone. In a way are two or two main characters that did work for them. Um, but so yeah, it's I'm, I'm hopeful with whoever kind of picks up not that like obviously Starscream and Windblader are important to other facets of the storylines in IDW right now. Um, right. It's it's it's not to say that we wouldn't get more of them, but like there does need to be a third title. Should I, what's happening on CyberCrood, right? Well, and that's where I, yeah, like I don't know exactly where this all goes from here. Unless, you know, possibly, I don't know, you know, does Optimus Prime now kind of take the role that Robots and Skys head earlier on where we kind of hopped between right certain storylines or certain locations. Um, and maybe we do know and I haven't been paying attention. That's a complete possibility here. Um, but I will say for what it's worth, I have great hope that the next people to really, or whoever really takes a hold of Windblade and Starscream next and really like the Gabbatcons and everybody handles them with the same amount of care and thoughtfulness that I feel really was such a driving reason that we on this show love to all of us so much because we do like this is, this is kind of our favorite title right now, I would say, um, which makes it an extra shame to see it close out. I mean, it's at least it got to go out the way that Miragerd wanted to and I totally respect all of that. Um, but it is always that thing where you never, you never quite know what is going to happen next, especially when it's something that you've enjoyed so much. It can be a little like, okay, well, we'll just have to wait and see and hope for the best. And I'm sure whatever it is will be good, of course. I don't know if you have our phone number, you have our Twitter account. Oh, God, hit us up. Yeah. We'll be there. We have a built-in fan base, obviously, people have all sorts of it. Uh, for sure, for sure. Uh, speaking of built-in fan base, I want to thank all of our lovely Patreons, Patreon patrons. That's, that's the one, um, that I'm speaking, of course, about good old David Cabrera, Jay Riley, Samuel Jocks, the fifth virtue associate of Stevens Kyle Schaefer, Betty Bouches, and Elizabeth Jackalope, who are hanging out on our Patreon. Um, thank you guys so much. We will check you at, I mean, at some point soon, I think we're going back to the last lights. So we'll see what swerves is like. We'll see. Yeah. Hopefully at some point, what's going on in McCatams. Again, I do have to put out there. I feel like if nothing else, swerves will at least be cleaner. Not to like make any, like that's not a, I mean, it's a little bit of a dig against swerve, but like I'm just being real here. That is very real. That is what we are about here is keeping it real. Oh, we keep a 100 over here. You guys know it. Um, I think that will do it for us. I think, um, there's not, I'm not a wealth of books coming out for the rest of the month. Right. So, uh, we, we, we may be taking a break. We may be cooking up something to fill up that said, but either way, keep it locked on our Twitter account. Twitter.com slash sound, wav cast. Uh, you'll get all the updates there as they come along. So yeah, well, for sure, keep everybody updated. That's the place where we will for sure. Let you know kind of what we're up to and where we're at. Uh, and I think that's it for this week. Is it not? Uh, I believe so. All right. Transforming odds. Um, uh, how does your summer transform? Nots. Uh, we're in the dog days. Transforming odds is almost back to school almost. Transforming, let's, let's go get you some pencil cases. Transforming odds. Do you need a protractor this year? I never remember what your kids start using protractors. New backpack? Transforming odds. Do you want a backpack with star screen on it? Oh, no. Oh, no. They're shaking their heads. They want wind blade. Oh, I get it. I get a truth. Gotcha.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx # Install the python-docx library, which provides the 'docx' module.\n",
        "from docx import Document\n",
        "\n",
        "# Create a new Word document\n",
        "doc = Document()\n",
        "\n",
        "# Add transcript to the document\n",
        "doc.add_heading(\"Podcast Transcript\", level=1)\n",
        "doc.add_paragraph(transcript)\n",
        "\n",
        "# Save the file\n",
        "transcript_file = \"podcast_transcript.docx\"\n",
        "doc.save(transcript_file)\n",
        "\n",
        "print(f\"✅ Transcript saved as {transcript_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFBPndzo2QY6",
        "outputId": "b5facb80-1441-4f12-821e-d7cb064665d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "✅ Transcript saved as podcast_transcript.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "# Create a new Word document\n",
        "doc = Document()\n",
        "\n",
        "# Add transcript to the document\n",
        "doc.add_heading(\"Podcast Transcript\", level=1)\n",
        "doc.add_paragraph(transcript)\n",
        "\n",
        "# Save the file\n",
        "transcript_file = \"podcast_transcript.docx\"\n",
        "doc.save(transcript_file)\n",
        "\n",
        "print(f\"✅ Transcript saved as {transcript_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez5iKbuTzqw-",
        "outputId": "12f9bef9-173a-44c2-930e-b9960e9bb414"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Transcript saved as podcast_transcript.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6ogcZqc3jLb",
        "outputId": "9385aec7-fdc7-4641-c145-53a3df45e137"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "print(nltk.data.find('tokenizers/punkt'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8zuO_SX4I_k",
        "outputId": "95e53631-e411-4376-899d-4d9cf53dfb72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/nltk_data/tokenizers/punkt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "\n",
        "nltk.data.path.append('/usr/local/share/nltk_data')\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdOQkJVr4LQ5",
        "outputId": "3cea1fd7-d0a7-470f-b913-ed1845c4eec4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall sumy nltk -y\n",
        "!pip install sumy nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "BUt0QyXk4NnS",
        "outputId": "b97a4d85-5df8-4881-a775-be2e9d66328d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: sumy 0.11.0\n",
            "Uninstalling sumy-0.11.0:\n",
            "  Successfully uninstalled sumy-0.11.0\n",
            "Found existing installation: nltk 3.9.1\n",
            "Uninstalling nltk-3.9.1:\n",
            "  Successfully uninstalled nltk-3.9.1\n",
            "Collecting sumy\n",
            "  Using cached sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting nltk\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.11/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from sumy) (2.32.3)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.11/dist-packages (from sumy) (24.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2025.1.31)\n",
            "Using cached sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Installing collected packages: nltk, sumy\n",
            "Successfully installed nltk-3.9.1 sumy-0.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              },
              "id": "2645b9b8549045c1b41543abc1ff3a19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy # Install the 'sumy' library before attempting to import it.\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Download the necessary data for tokenization\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "# Function to summarize text\n",
        "def summarize_text(text, num_sentences=5):\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    summarizer = LsaSummarizer()\n",
        "    summary = summarizer(parser.document, num_sentences)\n",
        "    return \" \".join(str(sentence) for sentence in summary)\n",
        "\n",
        "# Generate Summary\n",
        "summary = summarize_text(transcript, num_sentences=5)\n",
        "print(\"\\n📌 Podcast Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmBurlet2Mcy",
        "outputId": "4e5e1b79-689b-4224-e692-7964ad85afe2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sumy in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.11/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from sumy) (2.32.3)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.11/dist-packages (from sumy) (24.6.1)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from sumy) (3.9.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2025.1.31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📌 Podcast Summary:\n",
            " And so we also see a flashback explaining sort of what she sees about Starscream Spark in particular that he was cold constructed. And so we can see his this spark that she's now holding being placed in this seeker body of which there are many, which you know, we know that there are a bunch of seekers who all look the same. And of course, vigilance trying to just cover it in these ghost robots is like, you can't that's still not enough hang on. And it leaves just the two of them waking up, unhoking themselves from whatever machinery air actinid had going on in here. Um, but I will say for what it's worth, I have great hope that the next people to really, or whoever really takes a hold of Windblade and Starscream next and really like the Gabbatcons and everybody handles them with the same amount of care and thoughtfulness that I feel really was such a driving reason that we on this show love to all of us so much because we do like this is, this is kind of our favorite title right now, I would say, um, which makes it an extra shame to see it close out.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "# Function to save text to a Word file\n",
        "def save_to_word(transcript, summary, filename=\"Podcast_Transcript.docx\"):\n",
        "    doc = Document()\n",
        "\n",
        "    # Add Title\n",
        "    doc.add_heading(\"Podcast Transcript & Summary\", level=1)\n",
        "\n",
        "    # Add Transcript Section\n",
        "    doc.add_heading(\"🎙 Podcast Transcript\", level=2)\n",
        "    doc.add_paragraph(transcript)\n",
        "\n",
        "    # Add Summary Section\n",
        "    doc.add_heading(\"📌 Podcast Summary\", level=2)\n",
        "    doc.add_paragraph(summary)\n",
        "\n",
        "    # Save the document\n",
        "    doc.save(filename)\n",
        "    print(f\"✅ File saved successfully as: {filename}\")\n",
        "\n",
        "# Call the function with your transcript and summary\n",
        "save_to_word(transcript, summary, \"Podcast_Transcript.docx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtTCicyT24WH",
        "outputId": "fc0e6fbb-9b90-4908-f644-cffaab1045a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ File saved successfully as: Podcast_Transcript.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import re\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "# Function to read transcript from a Word file\n",
        "def read_transcript_from_docx(file_path):\n",
        "    doc = docx.Document(\"/content/Podcast_Transcript.docx\")\n",
        "    transcript = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "    return transcript\n",
        "\n",
        "# Function to extract key insights using LSA Summarization\n",
        "def extract_insights(transcript, num_sentences=5):\n",
        "    parser = PlaintextParser.from_string(transcript, Tokenizer(\"english\"))\n",
        "    summarizer = LsaSummarizer()\n",
        "    summary = summarizer(parser.document, num_sentences)\n",
        "    return [str(sentence) for sentence in summary]\n",
        "\n",
        "# Function to format content for social media\n",
        "def format_social_posts(insights):\n",
        "    twitter_posts = []\n",
        "    linkedin_post = \"\"\n",
        "\n",
        "    for insight in insights:\n",
        "        # Twitter (Split into multiple tweets if needed)\n",
        "        # Replace emojis with their textual representations\n",
        "        tweet = f\"💡 Key Insight: {insight} #PodcastInsights #DataTalks\"\n",
        "        twitter_posts.append(tweet[:280])  # Ensure it fits Twitter's character limit\n",
        "\n",
        "        # LinkedIn (Longer format)\n",
        "        # Replace emojis with their textual representations\n",
        "        linkedin_post += f\"\\n\\n✨ {insight}\"\n",
        "\n",
        "    linkedin_post += \"\\n\\nWhat are your thoughts? Drop a comment below! 🤔 #Podcast #Insights\"\n",
        "    return twitter_posts, linkedin_post\n",
        "\n",
        "# Function to save insights to a Word file\n",
        "def save_to_word(insights, twitter_posts, linkedin_post, filename=\"Podcast_Insights.docx\"):\n",
        "    doc = docx.Document()\n",
        "    doc.add_heading(\"Podcast Key Insights\", level=1)\n",
        "\n",
        "    for i, insight in enumerate(insights, 1):\n",
        "        doc.add_paragraph(f\"{i}. {insight}\")\n",
        "\n",
        "    doc.add_heading(\"Twitter Posts\", level=1)\n",
        "    for tweet in twitter_posts:\n",
        "        doc.add_paragraph(tweet)\n",
        "\n",
        "    doc.add_heading(\"LinkedIn Post\", level=1)\n",
        "    doc.add_paragraph(linkedin_post)\n",
        "\n",
        "    doc.save(filename)\n",
        "    print(f\"Insights saved to {filename}\")\n",
        "\n",
        "# Example usage\n",
        "file_path = \"Podcast_Transcript (1).docx\"  # Replace with actual file path\n",
        "transcript = read_transcript_from_docx(file_path)\n",
        "insights = extract_insights(transcript, num_sentences=5)\n",
        "twitter_posts, linkedin_post = format_social_posts(insights)\n",
        "save_to_word(insights, twitter_posts, linkedin_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACC-a98i880K",
        "outputId": "7ac0ca5c-6f61-45ea-8714-63953d96f869"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insights saved to Podcast_Insights.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58jJYprf_fTQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}